{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea45e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    raw_path = 'data/realtor-data.csv'\n",
    "    \n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"LocalSparkSession\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"24g\") \\\n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-XX:ReservedCodeCacheSize=256m\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"brokered_by\", StringType(), True),\n",
    "        StructField(\"status\", StringType(), True),\n",
    "        StructField(\"price\", DoubleType(), True),\n",
    "        StructField(\"bed\", IntegerType(), True),\n",
    "        StructField(\"bath\", IntegerType(), True),\n",
    "        StructField(\"acre_lot\", DoubleType(), True),\n",
    "        StructField(\"street\", StringType(), True),\n",
    "        StructField(\"city\", StringType(), True),\n",
    "        StructField(\"state\", StringType(), True),\n",
    "        StructField(\"zip_code\", StringType(), True),  \n",
    "        StructField(\"house_size\", DoubleType(), True),\n",
    "        StructField(\"prev_sold_date\", StringType(), True) \n",
    "    ])\n",
    "\n",
    "    raw_df = spark.read.csv(raw_path, header = True, schema = schema)\n",
    "    raw_df.cache()\n",
    "    \n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4edda72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/10 01:14:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+--------+---+----+--------+---------+----------+-----------+--------+----------+--------------+\n",
      "|brokered_by|  status|   price|bed|bath|acre_lot|   street|      city|      state|zip_code|house_size|prev_sold_date|\n",
      "+-----------+--------+--------+---+----+--------+---------+----------+-----------+--------+----------+--------------+\n",
      "|   103378.0|for_sale|105000.0|  3|   2|    0.12|1962661.0|  Adjuntas|Puerto Rico|   00601|     920.0|          NULL|\n",
      "|    52707.0|for_sale| 80000.0|  4|   2|    0.08|1902874.0|  Adjuntas|Puerto Rico|   00601|    1527.0|          NULL|\n",
      "|   103379.0|for_sale| 67000.0|  2|   1|    0.15|1404990.0|Juana Diaz|Puerto Rico|   00795|     748.0|          NULL|\n",
      "|    31239.0|for_sale|145000.0|  4|   2|     0.1|1947675.0|     Ponce|Puerto Rico|   00731|    1800.0|          NULL|\n",
      "|    34632.0|for_sale| 65000.0|  6|   2|    0.05| 331151.0|  Mayaguez|Puerto Rico|   00680|      NULL|          NULL|\n",
      "+-----------+--------+--------+---+----+--------+---------+----------+-----------+--------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df = load_data()\n",
    "raw_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780877a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               state| count|\n",
      "+--------------------+------+\n",
      "|                Ohio| 59207|\n",
      "|        Pennsylvania| 78373|\n",
      "|         Connecticut| 14008|\n",
      "|             Vermont|  2600|\n",
      "|         Puerto Rico|  3126|\n",
      "|      Virgin Islands|   895|\n",
      "|District of Columbia|  6625|\n",
      "|            Delaware|  8628|\n",
      "|       West Virginia| 12309|\n",
      "|            Missouri| 45145|\n",
      "|        Rhode Island|  8157|\n",
      "|             Georgia| 80977|\n",
      "|            Virginia| 68763|\n",
      "|             Wyoming|  4039|\n",
      "|          New Jersey| 48199|\n",
      "|            Maryland| 46052|\n",
      "|       Massachusetts| 38041|\n",
      "|           Louisiana| 25815|\n",
      "|       New Hampshire|  3642|\n",
      "|           Tennessee| 40964|\n",
      "|      South Carolina| 42367|\n",
      "|          California|227215|\n",
      "|            New York|103159|\n",
      "|               Maine|  5065|\n",
      "|            Colorado| 32293|\n",
      "|       New Brunswick|     1|\n",
      "|            Michigan| 42429|\n",
      "|      North Carolina| 85745|\n",
      "|             Alabama| 34053|\n",
      "|            Kentucky| 26316|\n",
      "|         Mississippi| 16255|\n",
      "|             Florida|249432|\n",
      "|           Wisconsin| 42390|\n",
      "|            Arkansas| 23045|\n",
      "|               Texas|208335|\n",
      "|                NULL|     8|\n",
      "|            Illinois| 85280|\n",
      "|          New Mexico| 21074|\n",
      "|             Indiana| 18840|\n",
      "|               Idaho| 16760|\n",
      "|           Minnesota| 43412|\n",
      "|        North Dakota|  4268|\n",
      "|            Nebraska|  6309|\n",
      "|            Oklahoma| 37140|\n",
      "|             Montana| 10059|\n",
      "|              Kansas| 14858|\n",
      "|                Iowa| 23033|\n",
      "|        South Dakota|  4690|\n",
      "|              Oregon| 32163|\n",
      "|                Utah| 14557|\n",
      "|              Hawaii|  7243|\n",
      "|              Nevada| 14667|\n",
      "|          Washington| 62461|\n",
      "|                Guam|   489|\n",
      "+--------------------+------+\n",
      "only showing top 54 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_by_state = raw_df.groupBy(\"state\").count()\n",
    "\n",
    "raw_by_state.show(54)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbd604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing_values(df: DataFrame):\n",
    "    missing_counts = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        missing_count = df.filter(col(column).isNull()).count()\n",
    "        missing_counts[column] = missing_count\n",
    "    \n",
    "    return missing_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e22203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=262144Kb used=29076Kb max_used=29103Kb free=233067Kb\n",
      " bounds [0x0000000104558000, 0x00000001061f8000, 0x0000000114558000]\n",
      " total_blobs=11045 nmethods=10088 adapters=869\n",
      " compilation: disabled (not enough contiguous free space left)\n",
      "{'brokered_by': 4533, 'status': 0, 'price': 1541, 'bed': 481317, 'bath': 511771, 'acre_lot': 325589, 'street': 10866, 'city': 1407, 'state': 8, 'zip_code': 299, 'house_size': 568484, 'prev_sold_date': 734297}\n"
     ]
    }
   ],
   "source": [
    "raw_missing = count_missing_values(raw_df)\n",
    "print(raw_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4f84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    columns_to_drop = ['prev_sold_date', 'brokered_by', 'street']\n",
    "    df = raw_df.drop(*columns_to_drop)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba6d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_na(df):\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d56040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR method\n",
    "def drop_outliers_1(df):\n",
    "    numeric_columns = ['bed', 'bath', 'acre_lot', 'house_size']\n",
    "\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile) grouped by zip_code\n",
    "    quantiles_df = df.groupBy('zip_code').agg(\n",
    "        *[F.expr(f'percentile_approx({col}, 0.25)').alias(f'{col}_Q1') for col in numeric_columns] +\n",
    "        [F.expr(f'percentile_approx({col}, 0.75)').alias(f'{col}_Q3') for col in numeric_columns]\n",
    "    )\n",
    "\n",
    "    # Join the quantiles with the original DataFrame\n",
    "    joined_df = df.join(quantiles_df, on='zip_code')\n",
    "\n",
    "    # Calculate IQR and identify outlier bounds\n",
    "    non_outlier_condition = (\n",
    "        (F.col('bed') >= F.col('bed_Q1') - 1.5 * (F.col('bed_Q3') - F.col('bed_Q1'))) &\n",
    "        (F.col('bed') <= F.col('bed_Q3') + 1.5 * (F.col('bed_Q3') - F.col('bed_Q1'))) &\n",
    "        (F.col('bath') >= F.col('bath_Q1') - 1.5 * (F.col('bath_Q3') - F.col('bath_Q1'))) &\n",
    "        (F.col('bath') <= F.col('bath_Q3') + 1.5 * (F.col('bath_Q3') - F.col('bath_Q1'))) &\n",
    "        (F.col('acre_lot') >= F.col('acre_lot_Q1') - 1.5 * (F.col('acre_lot_Q3') - F.col('acre_lot_Q1'))) &\n",
    "        (F.col('acre_lot') <= F.col('acre_lot_Q3') + 1.5 * (F.col('acre_lot_Q3') - F.col('acre_lot_Q1'))) &\n",
    "        (F.col('house_size') >= F.col('house_size_Q1') - 1.5 * (F.col('house_size_Q3') - F.col('house_size_Q1'))) &\n",
    "        (F.col('house_size') <= F.col('house_size_Q3') + 1.5 * (F.col('house_size_Q3') - F.col('house_size_Q1')))\n",
    "    )\n",
    "\n",
    "    cleaned_df = joined_df.filter(non_outlier_condition).drop(\n",
    "        *[f'{col}_Q1' for col in numeric_columns] + [f'{col}_Q3' for col in numeric_columns]\n",
    "    )\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "802e81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score method\n",
    "def drop_outliers_2(df):\n",
    "    numeric_columns = ['bed', 'bath', 'acre_lot', 'house_size']\n",
    "\n",
    "    # Calculate mean and standard deviation grouped by zip_code\n",
    "    mean_stddev_df = df.groupBy('zip_code').agg(\n",
    "        *[F.mean(col).alias(f'{col}_mean') for col in numeric_columns] +\n",
    "        [F.stddev(col).alias(f'{col}_stddev') for col in numeric_columns]\n",
    "    )\n",
    "\n",
    "    # Join the mean and stddev with the original DataFrame\n",
    "    joined_df = df.join(mean_stddev_df, on='zip_code')\n",
    "\n",
    "    # Calculate Z-scores and identify outliers based on Z-score threshold (|Z| > 3)\n",
    "    outlier_threshold = 3\n",
    "\n",
    "    non_outlier_condition = (\n",
    "        (F.abs((F.col('bed') - F.col('bed_mean')) / F.col('bed_stddev')) <= outlier_threshold) &\n",
    "        (F.abs((F.col('bath') - F.col('bath_mean')) / F.col('bath_stddev')) <= outlier_threshold) &\n",
    "        (F.abs((F.col('acre_lot') - F.col('acre_lot_mean')) / F.col('acre_lot_stddev')) <= outlier_threshold) &\n",
    "        (F.abs((F.col('house_size') - F.col('house_size_mean')) / F.col('house_size_stddev')) <= outlier_threshold)\n",
    "    )\n",
    "\n",
    "    cleaned_df = joined_df.filter(non_outlier_condition).drop(*[f'{col}_mean' for col in numeric_columns] + [f'{col}_stddev' for col in numeric_columns])\n",
    "\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fd07b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1073005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df = drop_columns(df)\n",
    "df = drop_na(df)\n",
    "df = drop_outliers_1(df)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55162f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                       (0 + 10) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               state| count|\n",
      "+--------------------+------+\n",
      "|                Utah|  7817|\n",
      "|              Hawaii|  3281|\n",
      "|           Minnesota| 26362|\n",
      "|                Ohio| 31226|\n",
      "|            Arkansas|  8459|\n",
      "|              Oregon| 16804|\n",
      "|               Texas|115246|\n",
      "|        North Dakota|  1953|\n",
      "|        Pennsylvania| 40898|\n",
      "|         Connecticut|  7706|\n",
      "|             Vermont|   996|\n",
      "|            Nebraska|  3414|\n",
      "|              Nevada|  8197|\n",
      "|         Puerto Rico|  1332|\n",
      "|          Washington| 37485|\n",
      "|            Illinois| 36852|\n",
      "|            Oklahoma| 19853|\n",
      "|District of Columbia|  2449|\n",
      "|            Delaware|  4838|\n",
      "|              Alaska|   648|\n",
      "|          New Mexico|  9102|\n",
      "|       West Virginia|  5332|\n",
      "|            Missouri| 23957|\n",
      "|        Rhode Island|  5295|\n",
      "|             Georgia| 40231|\n",
      "|             Montana|  3918|\n",
      "|            Virginia| 35942|\n",
      "|            Michigan| 16976|\n",
      "|                Guam|    92|\n",
      "|      North Carolina| 29267|\n",
      "|             Wyoming|  1395|\n",
      "|              Kansas|  8833|\n",
      "|          New Jersey| 15911|\n",
      "|            Maryland| 27609|\n",
      "|             Alabama| 11287|\n",
      "|             Arizona| 42567|\n",
      "|                Iowa| 13090|\n",
      "|       Massachusetts| 23226|\n",
      "|            Kentucky| 11798|\n",
      "|           Louisiana| 11119|\n",
      "|         Mississippi|  5703|\n",
      "|       New Hampshire|  1310|\n",
      "|           Tennessee| 13799|\n",
      "|             Florida| 96697|\n",
      "|             Indiana|  9149|\n",
      "|               Idaho|  9633|\n",
      "|      South Carolina| 13975|\n",
      "|        South Dakota|  1735|\n",
      "|          California|136276|\n",
      "|            New York| 39781|\n",
      "|           Wisconsin| 14390|\n",
      "|               Maine|  1752|\n",
      "|            Colorado| 15941|\n",
      "|      Virgin Islands|   101|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:===============>                                         (3 + 8) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "distinct_row_count_by_state = df.groupBy(\"state\").count()\n",
    "\n",
    "distinct_row_count_by_state.show(54)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f66ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df.write.csv(\"Data/cleaned_data.csv\", header=True, mode=\"overwrite\")\n",
    "df.coalesce(1).write.csv(\"Data/cleaned_data.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfd80e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------+----------+-----------+---------------+-----------------+----------+--------+---------+-------------+---------------+\n",
      "|               state|total_listings|price_median|bed_median|bath_median|acre_lot_median|house_size_median|price_mean|bed_mean|bath_mean|acre_lot_mean|house_size_mean|\n",
      "+--------------------+--------------+------------+----------+-----------+---------------+-----------------+----------+--------+---------+-------------+---------------+\n",
      "|                Utah|          7817|    570997.0|         4|          3|           0.17|           2402.0| 780533.29|    3.68|     2.94|         0.37|        2653.42|\n",
      "|              Hawaii|          3281|    825000.0|         3|          2|           0.44|           1296.0|1246148.97|    2.78|     2.25|         2.26|        1547.74|\n",
      "|           Minnesota|         26362|    329000.0|         3|          2|           0.22|           2068.0| 379074.34|    3.28|     2.33|          0.7|         2239.0|\n",
      "|                Ohio|         31226|    170000.0|         3|          2|            0.2|           1619.0| 212958.07|    3.19|     2.08|         0.49|         1796.0|\n",
      "|            Arkansas|          8459|    245000.0|         3|          2|           0.29|           1743.0| 276112.55|    3.22|     2.23|         1.82|        1881.44|\n",
      "|              Oregon|         16804|    499950.0|         3|          2|           0.16|           1720.0| 559164.36|     3.2|      2.3|         6.36|        1852.25|\n",
      "|               Texas|        115246|    327000.0|         3|          2|           0.18|           1951.0| 398990.27|    3.38|     2.58|         0.91|        2100.48|\n",
      "|        North Dakota|          1953|    275000.0|         3|          2|           0.19|           2044.0| 295668.04|    3.41|     2.35|         0.79|         2152.3|\n",
      "|        Pennsylvania|         40898|    249900.0|         3|          2|           0.17|           1635.0| 304601.92|    3.26|     2.22|          0.6|         1833.9|\n",
      "|         Connecticut|          7706|    384900.0|         3|          2|           0.37|           1832.0| 684636.91|    3.63|     2.69|         2.31|        2187.18|\n",
      "|             Vermont|           996|    339000.0|         3|          2|            1.0|           1953.0|  467338.0|     3.4|      2.4|         5.54|         2173.2|\n",
      "|            Nebraska|          3414|    250000.0|         3|          2|            0.2|           1850.0| 299108.75|    3.32|     2.41|         2.65|        2044.99|\n",
      "|              Nevada|          8197|    485000.0|         3|          2|           0.16|           1772.0| 634311.44|    3.25|     2.55|         0.39|        1972.14|\n",
      "|         Puerto Rico|          1332|    155000.0|         3|          2|            0.1|           1460.0| 482924.27|    3.55|      2.4|         0.26|         1820.9|\n",
      "|          Washington|         37485|    550000.0|         3|          2|           0.18|           1825.0| 679699.17|     3.3|     2.35|         0.49|        1961.67|\n",
      "|            Illinois|         36852|    264000.0|         3|          2|           0.19|           1680.0| 330146.02|    3.21|     2.37|         0.36|        1907.02|\n",
      "|            Oklahoma|         19853|    215000.0|         3|          2|           0.21|           1666.0| 249967.97|    3.17|     2.18|         1.12|        1807.66|\n",
      "|District of Columbia|          2449|    879900.0|         3|          3|           0.04|           1898.0|1084789.82|    3.51|     3.12|         0.06|        2141.28|\n",
      "|            Delaware|          4838|    350000.0|         3|          3|           0.21|           1950.0| 406629.33|    3.32|     2.53|         0.29|        2078.87|\n",
      "|              Alaska|           648|    429900.0|         3|          3|           0.46|           1934.0| 471401.38|    3.59|     2.58|         2.42|         2103.1|\n",
      "+--------------------+--------------+------------+----------+-----------+---------------+-----------------+----------+--------+---------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "numeric_columns = ['price', 'bed', 'bath', 'acre_lot', 'house_size']\n",
    "\n",
    "states_df = df.groupBy(\"state\").agg(\n",
    "    F.count(\"*\").alias(\"total_listings\"),\n",
    "    *[F.round(F.expr(f'percentile_approx({col}, 0.5)'), 2).alias(f'{col}_median') for col in numeric_columns],\n",
    "    *[F.round(F.mean(col), 2).alias(f'{col}_mean') for col in numeric_columns]\n",
    ")\n",
    "\n",
    "states_df.show()\n",
    "states_df.coalesce(1).write.csv(\"Data/aggregated_by_state\", header=True, mode=\"overwrite\")\n",
    "\n",
    "states_df.toPandas().to_csv(\"Data/aggregated_by_state.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8307224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------+------------+----------+-----------+---------------+-----------------+----------+--------+---------+-------------+---------------+\n",
      "|  state|zip_code|total_listings|price_median|bed_median|bath_median|acre_lot_median|house_size_median|price_mean|bed_mean|bath_mean|acre_lot_mean|house_size_mean|\n",
      "+-------+--------+--------------+------------+----------+-----------+---------------+-----------------+----------+--------+---------+-------------+---------------+\n",
      "|Alabama|   35004|            93|    279900.0|         3|          2|            0.2|           1866.0| 291843.25|    3.35|     2.54|         0.25|        1949.15|\n",
      "|Alabama|   35032|             1|    115000.0|         3|          1|           0.57|           1388.0|  115000.0|     3.0|      1.0|         0.57|         1388.0|\n",
      "|Alabama|   35033|            12|    325000.0|         4|          3|            2.5|           2312.0| 769058.33|    3.58|      3.0|         2.38|        2970.25|\n",
      "|Alabama|   35043|           123|    379900.0|         4|          3|           0.49|           2502.0| 423189.51|    3.85|     3.15|         0.57|        2469.54|\n",
      "|Alabama|   35046|            16|    239900.0|         3|          2|           0.72|           1688.0|  239622.5|    3.25|      2.0|         1.03|        1716.13|\n",
      "|Alabama|   35054|            32|    355000.0|         3|          2|           0.42|           2000.0| 376962.34|    3.22|     2.34|         0.71|        2125.34|\n",
      "|Alabama|   35068|            50|    200000.0|         3|          2|           0.36|           1542.0| 218021.36|     3.0|     1.94|         0.41|        1667.52|\n",
      "|Alabama|   35078|             8|    139700.0|         3|          2|           0.97|           1768.0|  216187.5|    3.13|      2.0|         1.33|        1780.63|\n",
      "|Alabama|   35089|             2|    179999.0|         3|          2|            0.9|           1461.0|  202499.5|     3.0|      2.0|        11.01|         1903.0|\n",
      "|Alabama|   35094|            70|    249900.0|         3|          2|           0.33|           1662.0| 249439.71|    3.27|     2.29|         0.39|        1773.93|\n",
      "|Alabama|   35096|            56|    225000.0|         3|          2|           0.33|           1663.0|  236051.7|    3.29|      2.3|          0.7|        1802.96|\n",
      "|Alabama|   35124|           210|    302000.0|         3|          3|           0.22|           2050.0| 333441.33|    3.31|     2.79|         0.29|         2101.7|\n",
      "|Alabama|   35136|             8|    339000.0|         3|          2|           1.68|           1985.0|  473987.5|    3.25|      3.0|         3.59|        2342.63|\n",
      "|Alabama|   35176|             2|    119900.0|         2|          1|           1.12|           1148.0|  132400.0|     2.5|      1.5|         1.58|         1474.0|\n",
      "|Alabama|   35208|            88|     85000.0|         3|          2|           0.17|           1318.0| 106531.25|     3.0|     1.59|         0.17|        1405.38|\n",
      "|Alabama|   35210|            75|    254900.0|         3|          2|           0.25|           1556.0| 263997.33|     3.0|     2.04|         0.28|         1549.2|\n",
      "|Alabama|   35444|             5|    150000.0|         3|          2|            1.5|           1568.0|  185980.0|     3.0|      2.0|         3.95|         2318.4|\n",
      "|Alabama|   35447|             4|    149900.0|         3|          1|           0.67|           1334.0|  182425.0|     3.0|     1.75|         1.03|        1498.75|\n",
      "|Alabama|   35461|             1|    429900.0|         4|          4|           12.3|           3763.0|  429900.0|     4.0|      4.0|         12.3|         3763.0|\n",
      "|Alabama|   35563|             7|     79900.0|         2|          2|            1.5|           1352.0|  81277.14|    2.14|     1.71|         1.17|        1303.57|\n",
      "+-------+--------+--------------+------------+----------+-----------+---------------+-----------------+----------+--------+---------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# numeric_columns = ['price', 'bed', 'bath', 'acre_lot', 'house_size']\n",
    "\n",
    "# # Group by state and zipcode and aggregate\n",
    "# zipcode_df = df.groupBy(\"state\", \"zip_code\").agg(\n",
    "#     F.count(\"*\").alias(\"total_listings\"),\n",
    "#     *[F.round(F.expr(f'percentile_approx({col}, 0.5)'), 2).alias(f'{col}_median') for col in numeric_columns],\n",
    "#     *[F.round(F.mean(col), 2).alias(f'{col}_mean') for col in numeric_columns]\n",
    "# )\n",
    "\n",
    "# zipcode_df.show()\n",
    "\n",
    "# # Write the DataFrame to CSV files, partitioned by state\n",
    "# zipcode_df.coalesce(1).write \\\n",
    "#     .option(\"header\", True) \\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .partitionBy(\"state\") \\\n",
    "#     .csv(\"Data/aggregated_by_zipcode\")\n",
    "\n",
    "\n",
    "numeric_columns = ['price', 'bed', 'bath', 'acre_lot', 'house_size']\n",
    "\n",
    "# Group by state and zipcode and aggregate\n",
    "zipcode_df = df.groupBy(\"state\", \"zip_code\").agg(\n",
    "    F.count(\"*\").alias(\"total_listings\"),\n",
    "    *[F.round(F.expr(f'percentile_approx({col}, 0.5)'), 2).alias(f'{col}_median') for col in numeric_columns],\n",
    "    *[F.round(F.mean(col), 2).alias(f'{col}_mean') for col in numeric_columns]\n",
    ")\n",
    "\n",
    "zipcode_df.show()\n",
    "\n",
    "# Get list of states\n",
    "states = [row.state for row in zipcode_df.select('state').distinct().collect()]\n",
    "\n",
    "# Create base directory if it doesn't exist\n",
    "import os\n",
    "base_dir = \"Data/aggregated_by_zipcode\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Write separate files for each state with consistent names\n",
    "for state in states:\n",
    "    state_df = zipcode_df.filter(F.col(\"state\") == state)\n",
    "    \n",
    "\n",
    "    (state_df\n",
    "        .toPandas()\n",
    "        .to_csv(f\"{base_dir}/{state.lower()}_zipcodes.csv\", index=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f6760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
